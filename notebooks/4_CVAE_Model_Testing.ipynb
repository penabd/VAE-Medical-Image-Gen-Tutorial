{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 4: Visualizing Reconstructions and Exploring the Latent Space\n",
    "\n",
    "In this tutorial, we analyze the behavior of the trained Conditional Variational Autoencoder (CVAE) by visualizing reconstructed images and probing the learned latent space.\n",
    "\n",
    "While training loss provides a quantitative measure of performance, qualitative inspection is also important for understanding what the model has actually learned.\n",
    "\n",
    "We will:\n",
    "\n",
    "- Visualize original chest X-ray images alongside their reconstructions\n",
    "\n",
    "- Examine how reconstruction quality varies across samples\n",
    "\n",
    "- Explore how the latent space changes as we modify the conditional label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.cvae import CVAE\n",
    "\n",
    "LATENT_DIM = 32\n",
    "LABEL_DIM = 1\n",
    "CHECKPOINT_PATH = \"/content/drive/MyDrive/cvae_best.pt\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CVAE(latent_dim=LATENT_DIM, label_dim=LABEL_DIM).to(device)\n",
    "model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Reconstructions\n",
    "\n",
    "To evaluate reconstruction quality, we compare the original input images with their corresponding reconstructions produced by the CVAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data.data_loader import get_chexpert_train_dataloader, get_chexpert_valid_dataloader\n",
    "\n",
    "\n",
    "valid_loader = get_chexpert_valid_dataloader()\n",
    "\n",
    "imgs, labels = next(iter(valid_loader))\n",
    "imgs = imgs.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    recon, _, _ = model(imgs, labels)\n",
    "\n",
    "# Plot a few examples\n",
    "n = 5\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "for i in range(n):\n",
    "    # Original\n",
    "    plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(imgs[i][0], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    if i == 0:\n",
    "        plt.title(\"Original\")\n",
    "\n",
    "    # Reconstruction\n",
    "    plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(recon[i][0], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    if i == 0:\n",
    "        plt.title(\"Reconstruction\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPoNdkSmE4i8V1i2ZuMElL1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
