{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZyMYMNowjfm"
      },
      "source": [
        "# Tutorial 2: Setting up the Conditional Variational Autoencoder in Pytorch\n",
        "\n",
        "In this tutorial, we implement a Conditional Variational Autoencoder (CVAE) for medical image generation. The CVAE extends the standard VAE by conditioning both the encoder and decoder on class labels. In our case, we condition the model on a binary pathology label (Pneumonia present or not).\n",
        "\n",
        "Conditioning allows the model to generate images that are not only realistic but also consistent with a specified clinical label, making CVAEs especially useful for synthetic medical image generation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmiYJruIzcod"
      },
      "source": [
        "## Conditional Variational Autoencoder Architecture Overview\n",
        "\n",
        "A CVAE consists of three main components:\n",
        "\n",
        "**Encoder**\n",
        "Maps an input image and label to a latent distribution parameterized by a mean and variance.\n",
        "\n",
        "**Latent Space with Reparameterization**\n",
        "Samples a latent vector from the learned distribution using the reparameterization trick.\n",
        "\n",
        "**Decoder**\n",
        "Reconstructs the image from the latent sample and the conditioning label.\n",
        "\n",
        "The latent representation in a VAE is probabilistic, which enables uncertainty modeling. We make sure to concatenate the label here so that the latent space, q(zâˆ£x,y) is explicitly conditioned on the class label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu9zmbtGzhDI"
      },
      "source": [
        "## Defining the Encoder\n",
        "\n",
        "The encoder takes as input:\n",
        "\n",
        "- A grayscale chest X-ray image $x \\in \\mathbb{R}^{1 \\times 128 \\times 128}$\n",
        "\n",
        "- A conditioning label $y \\in \\mathbb{R}^{1}$\n",
        "\n",
        "The image is passed through a series of convolutional layers to extract hierarchical feature representations.  \n",
        "The conditioning label is then concatenated with the flattened feature vector before predicting the parameters of the latent distribution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CX3zn04SzlTW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dim=32, label_dim=1):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1), nn.ReLU(),\n",
        "        )\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.fc_mu = nn.Linear(128*16*16 + label_dim, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(128*16*16 + label_dim, latent_dim)\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        h = self.conv(x)\n",
        "        h = self.flatten(h)\n",
        "        h = torch.cat([h, y], dim=1)\n",
        "        return self.fc_mu(h), self.fc_logvar(h)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pKV2gcNzmWx"
      },
      "source": [
        "## Defining the Decoder\n",
        "\n",
        "The decoder takes as input:\n",
        "\n",
        "- A sampled latent vector $z \\in \\mathbb{R}^{\\text{latent\\_dim}}$\n",
        "\n",
        "- The same conditioning label $y \\in \\mathbb{R}^{1}$\n",
        "\n",
        "The latent vector and conditioning label are concatenated and projected back into a spatial feature map, which is then upsampled using transposed convolution layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jDCzRz9nwpSX"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim=32, label_dim=1):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(latent_dim + label_dim, 128*16*16)\n",
        "        self.deconv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, 4, 2, 1), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 1, 4, 2, 1), nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, z, y):\n",
        "        h = torch.cat([z, y], dim=1)\n",
        "        h = self.fc(h).view(-1, 128, 16, 16)\n",
        "        return self.deconv(h)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBj5lvULzsaw"
      },
      "source": [
        "## Defining the CVAE class\n",
        "\n",
        "Training a CVAE involves minimizing the negative Evidence Lower Bound (ELBO), which consists of two terms:\n",
        "\n",
        "**Reconstruction Loss**\n",
        "Measures how well the reconstructed image matches the input.\n",
        "\n",
        "**KL Divergence Loss**\n",
        "Regularizes the latent distribution toward a unit Gaussian prior.\n",
        "\n",
        "A useful explanation of the concept can be found here: https://beckham.nz/2023/04/27/conditional-vaes.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "B1SB5-rLzbUk"
      },
      "outputs": [],
      "source": [
        "class CVAE(nn.Module):\n",
        "    def __init__(self, latent_dim=32, label_dim=1):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(latent_dim, label_dim)\n",
        "        self.decoder = Decoder(latent_dim, label_dim)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        mu, logvar = self.encoder(x, y)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        recon = self.decoder(z, y)\n",
        "        return recon, mu, logvar\n",
        "\n",
        "\n",
        "def cvae_loss(recon_x, x, mu, logvar):\n",
        "    batch_size = x.size(0)\n",
        "\n",
        "    recon_loss = nn.functional.mse_loss(\n",
        "        recon_x, x, reduction='sum'\n",
        "    ) / batch_size\n",
        "\n",
        "    kl = -0.5 * torch.sum(\n",
        "        1 + logvar - mu.pow(2) - logvar.exp()\n",
        "    ) / batch_size\n",
        "\n",
        "    return recon_loss + kl\n",
        "\n",
        "\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in loader:\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            recon, mu, logvar = model(imgs, labels)\n",
        "            loss = cvae_loss(recon, imgs, mu, logvar)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsc_rAK40C0K"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this tutorial, we implemented a Conditional Variational Autoencoder in PyTorch, including:\n",
        "\n",
        "A label-conditioned encoder and decoder\n",
        "\n",
        "The reparameterization trick for latent sampling\n",
        "\n",
        "A principled loss function based on variational inference\n",
        "\n",
        "In the next tutorial, we will train the CVAE on the CheXpert dataset and visualize reconstruction and generation results."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}