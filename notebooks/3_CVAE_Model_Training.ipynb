{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Training and Evaluating the CVAE\n",
    "\n",
    "In this tutorial, we train a Conditional Variational Autoencoder (CVAE) using PyTorch.\n",
    "We assume the model architecture, loss function, and dataset have already been defined in earlier tutorials.\n",
    "\n",
    "We will:\n",
    "\n",
    "Train the CVAE using labeled data\n",
    "\n",
    "Monitor training and validation loss\n",
    "\n",
    "Save the best-performing model for later use\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Configuration\n",
    "\n",
    "These are the the main training hyperparameters:\n",
    "\n",
    "- LATENT_DIM controls the dimensionality of the learned latent space\n",
    "\n",
    "- LABEL_DIM specifies the size of the conditional input\n",
    "\n",
    "- LR is the learning rate for the optimizer\n",
    "\n",
    "- EPOCHS determines how many passes we make over the dataset\n",
    "\n",
    "- CHECKPOINT_PATH specifies where to save the best model\n",
    "\n",
    "- LOAD_EXISTING allows us to resume training from a saved checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 32\n",
    "LABEL_DIM = 1\n",
    "LR = 1e-3\n",
    "EPOCHS = 50\n",
    "CHECKPOINT_PATH = \"/content/drive/MyDrive/cvae_best2.pt\"\n",
    "LOAD_EXISTING = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "We now bring together the model, optimizer, and data loaders to run the training loop. The code automatically uses a GPU if one is available, otherwise falling back to CPU. If LOAD_EXISTING is enabled, we load a previously saved model checkpoint before training. We obtain training and validation data loaders from the data module defined in earlier tutorials.\n",
    "\n",
    "For each training epoch, images and labels are moved to the appropriate device, the model produces reconstructions and latent statistics, the CVAE loss is computed and backpropagated, and the model parameters are updated using Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.cvae import CVAE\n",
    "from models.losses import cvae_loss\n",
    "from models.eval import evaluate\n",
    "\n",
    "from data.data_loader import get_chexpert_train_dataloader, get_chexpert_valid_dataloader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CVAE(latent_dim=LATENT_DIM, label_dim=LABEL_DIM).to(device)\n",
    "best_val_loss = float(\"inf\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "if LOAD_EXISTING:\n",
    "    model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=device))\n",
    "    print(\"Loaded existing model\")\n",
    "\n",
    "train_loader = get_chexpert_train_dataloader()\n",
    "valid_loader = get_chexpert_valid_dataloader()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        recon, mu, logvar = model(imgs, labels)\n",
    "        loss = cvae_loss(recon, imgs, mu, logvar)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    val_loss = evaluate(model, valid_loader, device)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{EPOCHS} | \"\n",
    "        f\"Train: {train_loss:.4f} | Val: {val_loss:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Checkpoint\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), CHECKPOINT_PATH)\n",
    "        print(\"Saved best model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "\n",
    "In this tutorial, we:\n",
    "\n",
    "- Trained a Conditional Variational Autoencoder using labeled data\n",
    "\n",
    "- Monitored training and validation loss across epochs\n",
    "\n",
    "- Saved model checkpoints based on validation performance\n",
    "\n",
    "In the next tutorial, we will visualize reconstructions and explore how the learned latent space captures meaningful structure in chest X-ray images"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPoNdkSmE4i8V1i2ZuMElL1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
