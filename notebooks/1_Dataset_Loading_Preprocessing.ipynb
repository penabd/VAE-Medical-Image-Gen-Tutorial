{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNULCaGvURQR4Gp1fUUOyIF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Tutorial 1: Loading the CheXpert Dataset and Data Preprocessing"],"metadata":{"id":"wBjxS5HVVu5w"}},{"cell_type":"markdown","source":["## Downloading the Dataset"],"metadata":{"id":"V7F2V9MaavI9"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6k1kuk_JVTym","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765405208759,"user_tz":420,"elapsed":38513,"user":{"displayName":"Bethany Pena","userId":"12783154964209810181"}},"outputId":"8f0d5629-e1c2-47fc-a4fd-e9fbca02b909"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n","Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.11.12)\n","Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n","Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n","Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n","Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n","Mounted at /content/drive\n","cp: cannot stat '/content/drive/MyDrive/kaggle.json': No such file or directory\n","chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/kaggle\", line 10, in <module>\n","    sys.exit(main())\n","             ^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/kaggle/cli.py\", line 68, in main\n","    out = args.func(**command_args)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 1741, in dataset_download_cli\n","    with self.build_kaggle_client() as kaggle:\n","         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 688, in build_kaggle_client\n","    username=self.config_values['username'],\n","             ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n","KeyError: 'username'\n","unzip:  cannot find or open chexpert.zip, chexpert.zip.zip or chexpert.zip.ZIP.\n"]}],"source":["!pip install kaggle\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# put kaggle.json in /content/drive/MyDrive\n","!mkdir ~/.kaggle\n","!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","\n","# download dataset\n","!kaggle datasets download -d ashery/chexpert\n","!unzip chexpert.zip -d chexpert\n"]},{"cell_type":"markdown","source":["## Upload to Colab\n","\n","Note that for this demonstration we use only a subset of the small training data set."],"metadata":{"id":"vGeq3RfRa7oY"}},{"cell_type":"code","source":[],"metadata":{"id":"eHSOoaz4lcu4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!rsync -avh --ignore-errors \"/content/drive/MyDrive/CheXpertSubset/CheXpert-v1.0-small/valid\" \"/content/chexpert/\"\n","!rsync -avh --ignore-errors \"/content/drive/MyDrive/CheXpertSubset/train.csv\" \"/content/chexpert/\"\n","!rsync -avh --ignore-errors \"/content/drive/MyDrive/CheXpertSubset/valid.csv\" \"/content/chexpert/\""],"metadata":{"id":"vgrcJHQ7lTi3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["SRC=\"/content/drive/MyDrive/CheXpertSubset/CheXpert-v1.0-small/train\"\n","DST=\"/content/chexpert/train\"\n","\n","!mkdir -p \"$DST\"\n","\n","import os\n","import subprocess\n","import time\n","\n","patients = sorted(os.listdir(SRC))\n","\n","BATCH_SIZE = 50\n","total = 2500 #len(patients)\n","\n","print(f\"Found {total} patient folders. Starting batch copy...\")\n","\n","for i in range(0, total, BATCH_SIZE):\n","    batch = patients[i:i+BATCH_SIZE]\n","    print(f\"\\n=== Copying batch {i//BATCH_SIZE + 1} ({i} to {i+len(batch)-1}) ===\")\n","\n","    for p in batch:\n","        src_path = os.path.join(SRC, p)\n","        dst_path = os.path.join(DST, p)\n","\n","        # Skip if already copied\n","        if os.path.exists(dst_path):\n","            print(f\"{p} already exists — skipping\")\n","            continue\n","\n","        # Attempt copy with retry\n","        retries = 3\n","        for attempt in range(1, retries+1):\n","            print(f\"Copying {p} (attempt {attempt})...\")\n","\n","            result = subprocess.run(\n","                [\"rsync\", \"-a\", src_path, DST],\n","                stderr=subprocess.PIPE,\n","                stdout=subprocess.PIPE,\n","                text=True\n","            )\n","\n","            if result.returncode == 0:\n","                print(f\"Finished {p}\")\n","                break\n","            else:\n","                print(f\"Error copying {p}: {result.stderr.strip()}\")\n","                print(\"Sleeping 5 seconds before retry...\")\n","                time.sleep(5)\n","\n","        if result.returncode != 0:\n","            print(f\"Failed to copy {p} after {retries} attempts.\")\n"],"metadata":{"id":"V09ENbGXlomO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Modify train.csv to match subset and paths: we only want one view"],"metadata":{"id":"Tg-yOHV7lyIZ"}},{"cell_type":"code","source":["def collect_valid_paths(root):\n","    valid = set()\n","    for root_dir, _, files in os.walk(root):\n","        for f in files:\n","            if f.endswith(\".jpg\"):\n","                rel = os.path.relpath(os.path.join(root_dir, f), root)\n","                valid.add(rel)\n","    return valid\n","\n","valid_paths = collect_valid_paths(\"/content/chexpert/train\")"],"metadata":{"id":"PVb2DpV0lwQH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.read_csv(\"/content/chexpert/train.csv\").fillna(0)\n","df[\"Path\"] = df[\"Path\"].str.replace(\"CheXpert-v1.0-small/\", \"\")\n","df = df[df[\"Path\"].str.contains(\"frontal\", na=False)]\n","\n","\n","df = df[df[\"Path\"].isin(valid_paths)]\n","df.to_csv(\"/content/chexpert/train_subset.csv\", index=False)\n","\n","print(f\"Filtered dataset size: {len(df)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N2iF-TJResjo","executionInfo":{"status":"ok","timestamp":1765613774131,"user_tz":420,"elapsed":1107,"user":{"displayName":"Bethany Pena","userId":"12783154964209810181"}},"outputId":"cd3af344-3b29-4cbf-a449-cdc6efc67a2a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Filtered dataset size: 0\n"]}]},{"cell_type":"code","source":["\n","df = pd.read_csv(\"/content/chexpert/train.csv\").fillna(0)\n","\n","# Strip both prefixes\n","df[\"Path\"] = (\n","    df[\"Path\"]\n","    .str.replace(\"CheXpert-v1.0-small/train/\", \"\", regex=False)\n",")\n","\n","# frontal only\n","df = df[df[\"Path\"].str.contains(\"frontal\", na=False)]\n","\n","# keep only files that exist\n","df = df[df[\"Path\"].isin(valid_paths)]\n","\n","print(f\"Filtered dataset size: {len(df)}\")\n","df.to_csv(\"/content/chexpert/train_subset.csv\", index=False)\n","\n","print(\"CSV Path example:\")\n","print(df[\"Path\"].iloc[0])\n","\n","print(\"\\nValid path example:\")\n","print(list(valid_paths)[0])\n"],"metadata":{"id":"R5kYlw1pl_T-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Creating a Pytorch Data Class"],"metadata":{"id":"DBUZ-yn1wzAW"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","\n","class CheXpertDataset(Dataset):\n","    def __init__(self, csv_path, root, label_name=\"Pneumonia\"):\n","        self.df = pd.read_csv(csv_path)\n","        self.df = self.df.fillna(0)\n","\n","        # Keep only rows with valid image paths\n","        self.df = self.df[self.df['Path'].notna()]\n","\n","        self.root = root\n","        self.label_name = label_name\n","\n","        self.transform = transforms.Compose([\n","            transforms.Resize((128, 128)),\n","            transforms.ToTensor()\n","        ])\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","\n","        rel_path = row[\"Path\"].replace(\"CheXpert-v1.0-small/\", \"\")\n","        img_path = os.path.join(self.root, rel_path)\n","\n","        # Skip missing images\n","        if not os.path.exists(img_path):\n","            print(f\"Missing image: {img_path}\")\n","            return self.__getitem__((idx + 1) % len(self))\n","\n","        img = Image.open(img_path).convert(\"L\")\n","        img = self.transform(img)\n","\n","        # Labels are -1,0,1 in CheXpert → convert to {0,1}\n","        y = torch.tensor([1.0 if row[self.label_name] == 1 else 0.0], dtype=torch.float32)\n","\n","        return img, y\n","\n"],"metadata":{"id":"m5siUnSnw1me","executionInfo":{"status":"ok","timestamp":1765647019360,"user_tz":420,"elapsed":6,"user":{"displayName":"Bethany Pena","userId":"12783154964209810181"}}},"execution_count":null,"outputs":[]}]}